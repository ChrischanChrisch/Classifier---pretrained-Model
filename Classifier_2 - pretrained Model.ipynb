{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier with pretrained model\n",
    "\n",
    "Images per class should be located in subfolders (name=Class name) in folder \"Training_imgs\"\n",
    "pretrained model should be located in folder \"Pretrained_Models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model \n",
    "step 1:  load all the libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import skimage\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D,Dense,Flatten,MaxPool2D,Activation,Dropout,UpSampling2D,add,Conv2DTranspose,concatenate,multiply,GlobalMaxPooling2D,GlobalAveragePooling2D,Input\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: setting some train hyperparameters and location for the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "learn_rate = 0.0001\n",
    "#reg = l2(0.0005)\n",
    "\n",
    "i = 0\n",
    "path = r'C:\\Tensorflow2\\workspace\\Classifier_2\\Training_imgs'\n",
    "subfolders = [f.name for f in os.scandir(path) if f.is_dir()]\n",
    "print('Numbers of Classes: ', len(subfolders))\n",
    "print(subfolders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: loading the images from the subfolders and building a training and test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorie_images = []\n",
    "categorie_label = []\n",
    "categorie_name = []\n",
    "#categorie = []\n",
    "#label = []\n",
    "for i in range(0, len(subfolders)):\n",
    "    categorie = []\n",
    "    label = []\n",
    "    for img in os.listdir(path+'\\\\'+subfolders[i]):\n",
    "        #print(img)\n",
    "        img_1 = io.imread(path+'\\\\'+subfolders[i]+'\\\\'+img)\n",
    "        img_1 = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n",
    "        img_1 = cv2.resize(img_1, (250, 160))\n",
    "        #img_1 = resize(img_1, (img_1.shape[0] / 4, img_1.shape[1] / 4))\n",
    "        #img_1 = resize(img_1, (img_1.shape[0], img_1.shape[1]))\n",
    "        categorie.append(img_1)\n",
    "        label.append(i)\n",
    "        shape = img_1.shape\n",
    "    categorie_images.append(categorie)\n",
    "    categorie_label.append(label)\n",
    "    categorie_name.append(subfolders[i])\n",
    "\n",
    "for i in range(0, len(categorie_images)):\n",
    "    print('No. in: ', categorie_name[i], ' are: ', len(categorie_images[i]))\n",
    "\n",
    "all_together = categorie_images[0]+categorie_images[1]+categorie_images[2]+categorie_images[3]+categorie_images[4]\n",
    "print('All_together are:', len(all_together))\n",
    "train_X = np.array(all_together)\n",
    "\n",
    "labels = categorie_label[0]+categorie_label[1]+categorie_label[2]+categorie_label[3]+categorie_label[4]\n",
    "\n",
    "x_train = train_X.astype('float32') / train_X.max()\n",
    "x_train = np.reshape(x_train, (len(x_train), 160, 250, 3))\n",
    "\n",
    "train_labels = np.asarray(pd.get_dummies(labels), dtype=np.int8)\n",
    "\n",
    "train_x, train_y = shuffle(x_train, train_labels)\n",
    "train_x, test_x, train_y, test_y = train_test_split(train_x, train_y, test_size=0.05, shuffle=True)\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.05, shuffle=True)\n",
    "val_x, val_y = shuffle(val_x, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Building the model from a pretrained one / \n",
    "other weigths can be downlaoded here: https://github.com/fchollet/deep-learning-models/releases/tag/v0.1\n",
    "https://github.com/fchollet/deep-learning-models/releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights=r'C:\\KI\\KI_Inspection\\Stent_Type_BES\\04_Pretrained_Model\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(160, 250, 3))\n",
    "x = base_model.get_layer('block3_conv3').output\n",
    "x.trainable = False\n",
    "# # # # # #inputs=Input(shape=(160,200,3))\n",
    "# # # # # #x=base_model(inputs)\n",
    "# # # # # #visible=Input(shape=(160,200,3))\n",
    "# # # # # #conv_8=Conv2D(128,kernel_size=3,padding='same',activation='relu',name='conv2d_2')(x)\n",
    "# # # # # #conv_9=Conv2D(128,kernel_size=3,padding='same',activation='relu',name='conv2d_3')(conv_8)\n",
    "global_pool = GlobalAveragePooling2D()(x)\n",
    "hidden_1 = Dense(50, activation='relu')(global_pool)\n",
    "drop_2 = Dropout(0.5)(hidden_1)\n",
    "output_1 = Dense(5, activation='softmax')(drop_2)\n",
    "model = Model(inputs=base_model.input, outputs=output_1)\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5:  Run the training / the trained model will be saved in \"Final_Model\" with the name \"Model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_point = keras.callbacks.ModelCheckpoint(filepath=r'C:\\Tensorflow2\\workspace\\Classifier_2\\Final_Model\\Model.h5',monitor='val_loss',save_best_only=True)\n",
    "log_dir = os.path.join(\"logs\", \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensor_board = TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_images=True)\n",
    "callbacks_list = [check_point, tensor_board]\n",
    "\n",
    "opt = Adam(lr=learn_rate, decay=0.000009)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, callbacks=callbacks_list, verbose=1, validation_data=(val_x, val_y))\n",
    "\n",
    "score = model.evaluate(test_x, test_y, verbose=0)\n",
    "print('Test loss: ', score[0])\n",
    "print('Test accuracy: ', score[1])\n",
    "print(\"Evaluation Accuracy %s: %.2f%%\" %(model.metrics_names[1], score[1]*100))\n",
    "#model.save(r'C:\\Users\\csadmin\\PycharmProjects\\April_DAE\\End_Classification\\07_Training_Data_Close\\05_May_26_Classification_with_Categories\\03_Training_Scripts\\08_July15_Resnet_bs_16_conv3_block3\\July15_Last_epoch.h5')\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(r'C:\\Tensorflow2\\workspace\\Classifier_2\\Final_Model\\Model.h5')\n",
    "Text = ''\n",
    "x1 = 550\n",
    "x2 = 1000\n",
    "y1 = 200\n",
    "y2 = 450\n",
    "\n",
    "for imag in glob.glob(r\"C:\\Tensorflow2\\workspace\\Classifier_2\\Test_imgs/*.jpg\"):\n",
    "    print(imag)\n",
    "\n",
    "    frame = cv2.imread(imag)\n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "    disp = frame.copy()\n",
    "    frame = frame[y1:y2, x1:x2]\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    classify_img = cv2.resize(frame, (250, 160))\n",
    "    classify_img = img_to_array(classify_img)\n",
    "    classify_img = np.array(classify_img, dtype=\"float\")\n",
    "    classify_img = classify_img.astype('float32') / classify_img.max()\n",
    "    classify_img = np.reshape(classify_img, (-1, 160, 250, 3))\n",
    "\n",
    "    classifier = model.predict(classify_img, batch_size=1)\n",
    "    prediction = np.argmax(classifier)\n",
    "    percent = classifier[0][prediction]*100\n",
    "\n",
    "    if prediction == 0:\n",
    "        Text = 'Design: S '\n",
    "        print(Text, percent)\n",
    "    elif prediction == 1:\n",
    "        Text = 'Design: Invalid '\n",
    "        print(Text, percent)\n",
    "    elif prediction == 2:\n",
    "        Text = 'Design: Wrong '\n",
    "        print(Text, percent)\n",
    "    elif prediction == 3:\n",
    "        Text = 'Design: M'\n",
    "        print(Text, percent)\n",
    "    elif prediction == 4:\n",
    "        Text = 'Design: L '\n",
    "        print(Text, percent)\n",
    "\n",
    "    cv2.putText(disp, Text, (70, 80), cv2.FONT_HERSHEY_DUPLEX, 1.0, (255, 255, 255),\n",
    "                lineType=cv2.LINE_AA)\n",
    "    cv2.rectangle(disp, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "    cv2.imshow(\"Image\", disp)\n",
    "\n",
    "    k = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
